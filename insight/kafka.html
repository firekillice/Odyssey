<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>kafka 一篇入魂 | 吹风的坚果</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="">
    
    <link rel="preload" href="/assets/css/0.styles.280e3266.css" as="style"><link rel="preload" href="/assets/js/app.598d8060.js" as="script"><link rel="preload" href="/assets/js/2.4f2e74d3.js" as="script"><link rel="preload" href="/assets/js/9.d75e3788.js" as="script"><link rel="prefetch" href="/assets/js/10.e79c846a.js"><link rel="prefetch" href="/assets/js/11.d336f07f.js"><link rel="prefetch" href="/assets/js/12.ebf97c23.js"><link rel="prefetch" href="/assets/js/13.f9fc41aa.js"><link rel="prefetch" href="/assets/js/14.1d241cc3.js"><link rel="prefetch" href="/assets/js/15.a81b04cd.js"><link rel="prefetch" href="/assets/js/16.dc1fed68.js"><link rel="prefetch" href="/assets/js/17.d6c05371.js"><link rel="prefetch" href="/assets/js/18.38605d93.js"><link rel="prefetch" href="/assets/js/19.5d79d441.js"><link rel="prefetch" href="/assets/js/20.51402678.js"><link rel="prefetch" href="/assets/js/21.ad3ac771.js"><link rel="prefetch" href="/assets/js/22.85fe41d1.js"><link rel="prefetch" href="/assets/js/23.78ae8a1e.js"><link rel="prefetch" href="/assets/js/24.4c1e0764.js"><link rel="prefetch" href="/assets/js/25.a6336fbd.js"><link rel="prefetch" href="/assets/js/26.7bc87b9c.js"><link rel="prefetch" href="/assets/js/27.a8bcba1d.js"><link rel="prefetch" href="/assets/js/28.2a827e55.js"><link rel="prefetch" href="/assets/js/3.3a22e7ff.js"><link rel="prefetch" href="/assets/js/4.03d8bd1f.js"><link rel="prefetch" href="/assets/js/5.6607a218.js"><link rel="prefetch" href="/assets/js/6.125d6abe.js"><link rel="prefetch" href="/assets/js/7.bb4679bc.js"><link rel="prefetch" href="/assets/js/8.584c5789.js">
    <link rel="stylesheet" href="/assets/css/0.styles.280e3266.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">吹风的坚果</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/protocol/" class="nav-link">
  协议
</a></div><div class="nav-item"><a href="/book/" class="nav-link">
  读书
</a></div><div class="nav-item"><a href="/insight/" class="nav-link router-link-active">
  浅见
</a></div><div class="nav-item"><a href="/cncf/" class="nav-link">
  云原生
</a></div><div class="nav-item"><a href="/security/" class="nav-link">
  安全
</a></div><div class="nav-item"><a href="/alg/" class="nav-link">
  算法
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/protocol/" class="nav-link">
  协议
</a></div><div class="nav-item"><a href="/book/" class="nav-link">
  读书
</a></div><div class="nav-item"><a href="/insight/" class="nav-link router-link-active">
  浅见
</a></div><div class="nav-item"><a href="/cncf/" class="nav-link">
  云原生
</a></div><div class="nav-item"><a href="/security/" class="nav-link">
  安全
</a></div><div class="nav-item"><a href="/alg/" class="nav-link">
  算法
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>浅见</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/insight/va-2-pa.html" class="sidebar-link">用虚拟地址如何找到物理地址</a></li><li><a href="/insight/mem-2-cache.html" class="sidebar-link">内存和缓存的如何聊天</a></li><li><a href="/insight/hdd-2-mem.html" class="sidebar-link">磁盘和内存如何聊天</a></li><li><a href="/insight/kafka.html" aria-current="page" class="active sidebar-link">kafka 一篇入魂</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/insight/kafka.html#引子" class="sidebar-link">引子</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#先有请各种角色入场" class="sidebar-link">先有请各种角色入场</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#broker出列-做个简单的自我介绍" class="sidebar-link">Broker出列，做个简单的自我介绍</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#老王提问-消息如果只在一台机器上-容量不够怎么办" class="sidebar-link">老王提问：消息如果只在一台机器上，容量不够怎么办？</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#老王提问-如果消息的机器磁盘坏掉了怎么办" class="sidebar-link">老王提问：如果消息的机器磁盘坏掉了怎么办？</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/insight/kafka.html#副本工作机制概述" class="sidebar-link">副本工作机制概述</a></li></ul></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#生产者如何工作" class="sidebar-link">生产者如何工作？</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/insight/kafka.html#ack机制" class="sidebar-link">ACK机制</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#做个简单的实验" class="sidebar-link">做个简单的实验</a></li></ul></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#消费者如何工作" class="sidebar-link">消费者如何工作？</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/insight/kafka.html#消费的次数保证" class="sidebar-link">消费的次数保证</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#幂等" class="sidebar-link">幂等</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#事务" class="sidebar-link">事务</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#小结" class="sidebar-link">小结</a></li></ul></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#下面请老王给我们实战" class="sidebar-link">下面请老王给我们实战</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/insight/kafka.html#重要集群配置" class="sidebar-link">重要集群配置</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#集群" class="sidebar-link">集群</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#topic" class="sidebar-link">Topic</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#生产者命令" class="sidebar-link">生产者命令</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#消费者命令" class="sidebar-link">消费者命令</a></li></ul></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#总结" class="sidebar-link">总结</a></li><li class="sidebar-sub-header"><a href="/insight/kafka.html#引用" class="sidebar-link">引用</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="kafka-一篇入魂"><a href="#kafka-一篇入魂" class="header-anchor">#</a> kafka 一篇入魂</h1> <h2 id="引子"><a href="#引子" class="header-anchor">#</a> 引子</h2> <p>想象一个场景，如果A进程在一个瞬间向B进程发送了大量的数据，如果B的算力不够而无法马上处理，可能就会有消息被丢弃，而如果业务要求消息不能丢，这种场景应该怎么办呢？这个需要一个消息队列将消息存起来。本文就将讨论消息队列中的佼佼者--Kafka,这个名字就是来自于小说家卡夫卡。本文的内容是基于KRaft模式的kafka版本。</p> <h2 id="先有请各种角色入场"><a href="#先有请各种角色入场" class="header-anchor">#</a> 先有请各种角色入场</h2> <ul><li>Message、Event、消息：就是队列传输的对象</li> <li>生产者(Producer): 就是生产消息的家伙</li> <li>消费者(Consumer): 就是消费消息的家伙</li> <li>Broker: 就是承载Kafka服务的家伙，一般结伴出现</li> <li>主题(Topic): 就是消息的目录，写消息入需要指定主题，此处可不能迷路</li> <li>分区(Partition): 同一个主题的消息会被放到不同的分区中，消息在分区中排队，遵循FIFO(先进先出)原则。
演员介绍完毕，下面我们进入正题</li></ul> <h2 id="broker出列-做个简单的自我介绍"><a href="#broker出列-做个简单的自我介绍" class="header-anchor">#</a> Broker出列，做个简单的自我介绍</h2> <ul><li>我是使用Scala编写的，运行在JVM虚拟机上</li> <li>我可以将消息持久化到磁盘，保证断电还有数据</li> <li>我的消息是通过发布订阅(Puslish-And-Subscribe)的模式进行生产与消费的</li> <li>我写数据的时候，不会太麻烦磁盘老哥，我只顺序写入，避免随机写入，提高磁盘写入效率，这样我和磁盘老哥配合的很好，它总能非常快的完成我的任务。</li> <li>我非常懒，不会主动Push消息到消费者，消费者采用拉取（Pull）模式获取数据</li> <li>我还有个提高效率的秘籍，使用<code>sendfile</code>可以<code>**零拷贝**</code>的方式将数据直接从文件系统发送到网络系统，实现两个不同系统的文件描述符之间的数据直传，感谢OS</li> <li>producer或者consumer要想与我通信，需要通过TCP协议</li></ul> <h2 id="老王提问-消息如果只在一台机器上-容量不够怎么办"><a href="#老王提问-消息如果只在一台机器上-容量不够怎么办" class="header-anchor">#</a> 老王提问：消息如果只在一台机器上，容量不够怎么办？</h2> <p>那就使用分区，分区可以将数据均匀的分布在多台机器上，你就获得了一个超能力----<code>无限长的数组</code>。下面我来仔细介绍一下分区。</p> <ul><li>请先看图 <img src="/assets/img/kafka-partition.7b50d9cf.jpg" alt="kafka-partion"></li> <li>一个Topic可以生成多个分区，这些分区可能被分配到多个broker上</li> <li>每个分区中是一个队列，所以分区中是有序的数据</li> <li>每个消息都有一个<code>整数编号offset</code>，该值单调递分区唯一，从0开始为队首，最大值为队尾</li> <li>因为分区内有序，而对于<code>整个topic而言是无序</code>的，或者说是偏序的。</li></ul> <h2 id="老王提问-如果消息的机器磁盘坏掉了怎么办"><a href="#老王提问-如果消息的机器磁盘坏掉了怎么办" class="header-anchor">#</a> 老王提问：如果消息的机器磁盘坏掉了怎么办？</h2> <p>kafka支持多个副本，增加副本个数就能提高容灾</p> <ul><li>每个分区都会生成一个副本集，有一个leader和follower(数目可能为0)两种角色的分区数据，数据的读写都发生在Leader上，Follower只同步数据
<img src="/assets/img/kafka-replication.a74ab171.jpg" alt="kafka-replication"></li> <li>Leader维护ISR(In-Sync Replicas), 说白了，就是这些副本目前同步了，比如[2,4,5]构成了一个副本集, 2为Leader，ISR可能是[2],[2,4],[2,4,5]等，ISR中一定包含Leader
<img src="/assets/img/kafka-isr-osr.bc6b0762.jpg" alt="kafka-isr-osr"></li> <li>不同的副本一定在不同的broker上，否则就没有意义了，副本的个数在创建topic的时候或者使用默认值，如果broker个数少于该值，则会创建topic失败</li></ul> <h3 id="副本工作机制概述"><a href="#副本工作机制概述" class="header-anchor">#</a> 副本工作机制概述</h3> <ul><li>我们先看一下分区上的2个重要的位置
<ul><li>High Watermark(HW): 表示该位置以前的数据都拷贝到各个分区中了，消费者可以放心食用了，注意<code>HW所在的位置是未提交的</code></li> <li>Log End Offset(LEO): 表示下一个写入的位置，即<code>该处还没有数据</code> <img src="/assets/img/kafka-4-pos-for-partition.27940bfa.jpg" alt="kafka-4-pos-for-partition"></li></ul></li> <li>我们知道了以下几个知识点
<ol><li>HW是消费者能使用的数据的最大位置</li> <li>所有数据都是从Leader副本推送和拉取的</li> <li>Leader的HW就决定了消费者组能消费的最大Offset，只要Leader的HW向前推进就能持续提供消费者数据</li></ol></li></ul> <h4 id="ok-下面我们来看一下具体的流程"><a href="#ok-下面我们来看一下具体的流程" class="header-anchor">#</a> OK，下面我们来看一下具体的流程</h4> <ul><li><img src="/assets/img/kafka-replicat-procedure.4b5e4988.jpg" alt="kafka-replicat-procedure"></li> <li>Step 0:初始状态，Leader维护了自己的HW与LEO、Follower的remote LEO，所有值都为0，Follower维护了自己的HW，LEO，值为0</li> <li>Step 1:
<ul><li>生产者推送了一条消息</li> <li>Leader的LEO向后偏移为1，HW不变，因为Follower还没有同步</li></ul></li> <li>Step 2:
<ul><li>Follower同步了一次，请求Offset=0开始的数据</li> <li>Leader返回自己的HW=0</li> <li>Follower写盘，LEO后移一位变为1, 因为Leader的HW=0，Follower设置HW=0=Min(Leader.HW, Self.LEO)，Follower的HW不能大于Leader的，也不能大于自己的LEO</li></ul></li> <li>Step 3:
<ul><li>Follower再次同步，请求Offset=1开始的数据</li> <li>Leader发现offset=0的地方已经被follower同步了，随即将自己的HW=1=Max(Leader.HW, Min(FollowerA.LEO, FollowerB.LEO ...)) (这个公式可以如此理解：<code>**当HW较小的时候，HW的更新由Followers的LEO决定，取所有Follower全都同步的部分; 当HW较大的时候则忽略follower的影响，因为是相对滞后的follower在同步数据**</code>)，表示0可以被消费了，然后将HW=1返回给Follower</li> <li>Follower没有拿到任何数据，但是看到Leader的HW=1了，此时设置自己的HW=1=Min(Leader.HW,Self.LEO)，此时Producer写入的一条数据全部同步完毕。</li></ul></li></ul> <h4 id="上述流程中如果发生了step-3的返回消息丢失"><a href="#上述流程中如果发生了step-3的返回消息丢失" class="header-anchor">#</a> 上述流程中如果发生了Step 3的返回消息丢失</h4> <p>假设Step 3的返回消息Follower没有收到，Follower挂了，然后自动重启后发现自己的HW=0，LEO=1，则Follower会将仅有的一条数据清理(因为这条数据未经确认)，然后再从Leader重新拉取消息，如果这个时候恰好Leader 挂了，Follower荣幸的成为了Leader，消息就丢失了。</p> <p>如何解决这个问题呢，Kafka引入了Epoch，该值单调递增。每个分区都会保存经历过的&lt;Epoch,Offset&gt;列表，放入到日志文件<code>leader-epoch-checkpoint</code>，这里面相当于按阶段保存了数据的起始位置。</p> <p>让我们重新回到前面的问题，如果Follower 挂掉又启动后，它不会自己将自己截肢，而是想办法找到一个<code>参考点</code>，那就去找Leader要它的LEO，发现Epoch和LEO都和自己的一样大，那么Follower理所当然的认为<code>老子的数据没错啊</code>，那我就不截肢了，数据保持了同步。其实还有很多种情形可以讨论，这里就不展开了。我看了很多资料后，总结来看有一些几点看法:</p> <ul><li>使用Epoch可以丢弃网络中的旧Leader的数据，还可以丢弃日志中脏数据。举个例子，如果有个Follower启动后发现自己的最大Epoch为2，可是请求Leader后发现Leader为1，它就会删除所有的Epoch为2的数据</li> <li>执行Leader的强一致性，Follower无脑与Leader看齐。如果Follower发现自己和Leader的Epoch一样，但是Offset差很多，就一直拉取消息就行了。如果Epoch小，则也是一直拉取；如果大的话，就该删除数据了。</li> <li>Leader和Follower都在努力工作让大家的状态是一致的，这个一致以Leader为标准，执行强一致性。</li></ul> <h4 id="leader如何正确的切换呢"><a href="#leader如何正确的切换呢" class="header-anchor">#</a> Leader如何正确的切换呢</h4> <p>如果Follower知道如何从Leader同步数据，那么关于数据的正确性就剩下如何保证Leader正确的切换了？首先，什么是正确，对于用户而言，<code>肯定是我提交的数据都应该还在</code>，对于系统而言就是应该<code>找到维护最新提交数据的节点做为Leader</code>。这里就是那个<code>2n+1</code>的场景，要想保证一台机器挂掉不影响，则需要3台机器；2台机器挂掉不影响，则需要5台机器。如果只有1个节点，则是没有任何保证的，比如<code>min.insync.replicas=1或者acks=1</code>的时候，即使有epoch也做不到数据的安全性。</p> <p>分布式系统的状态转换应当始终保证从一个一致的状态切换到另一个一致的状态，S1=F(S0)，如果中间出现问题，那么需要找到上一个正确状态。由Leader维护该正确的状态，如果Leader遇到了模糊的状态，那就应该重置为上一个状态。如果3个节点一个节点挂了，还剩2个节点，因为他们拥有者最新的状态，他们就能投票找到新的leader，但是这时候有可能存在进行了一半的脏数据，但是原来的Leader已经没有了，新的Leader无法决策原来的数据，则该数据就丢失了。但是因为这个数据在上一任Leader执行失败了，所以业务端应该是返回失败了，用户并不会觉得是数据丢失。</p> <h2 id="生产者如何工作"><a href="#生产者如何工作" class="header-anchor">#</a> 生产者如何工作？</h2> <ul><li><img src="/assets/img/kafka-producer.9786c15d.jpg" alt="kafka-producer.jpg"></li> <li>生产者放入的数据根据key进行hash或者随机后放入对应的分区</li> <li>前文说到topic整体是偏序的，但是可以局部有序，生产者可以使用key进行控制，相同的key放入相同的分区中，这样可以保证某个key的所有数据有序</li> <li>生产者只能将数据放到分区的尾部</li> <li>消费者写入消息后，如何知道写入成功与否呢，Kafka提供ACK机制</li></ul> <h3 id="ack机制"><a href="#ack机制" class="header-anchor">#</a> ACK机制</h3> <p>Kafka提供了3种不同级别的ACK确认机制，确认机制是由Producer选择的，在新建Producer的配置中设置，这样不同的producer可以根据自己的场景灵活的进行选择，关键数据可以采用安全级别较高的方式，普通的日志可以采用较快的方式。</p> <ul><li>acks=0(None): 接口直接返回，不保证任何写入</li> <li>acks=1(Leader): Leader写入成功就返回</li> <li>acks=-1(ALL): ISR中所有节点写入成功才返回，当这个配置起效的时候，broker中的配置项<code>min.insync.replicas=2</code>也参与约束，ISR中的个数不能小于该值，否则当只有一个副本的时候，<code>acks=-1</code>退化为<code>acks=1</code>。如果<code>min.insync.replicas=2</code>，但是副本个数为5，则写消息Leader和一个副本写成功就会返回。该值配置为1的时候，则与<code>acks=1</code>效果一样，但是速度会快，如果配置多一些，则速度回慢一些，但是更安全。</li></ul> <h3 id="做个简单的实验"><a href="#做个简单的实验" class="header-anchor">#</a> 做个简单的实验</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>string bootstrapServers = &quot;10.10.30.71:29292&quot;;
string topic = &quot;mytest2&quot;;

var config = new ProducerConfig
{
    BootstrapServers = bootstrapServers,
    Acks = Acks.Leader,
    LingerMs = 5,
    CompressionType = CompressionType.Snappy
};
using var producer = new ProducerBuilder&lt;string, string&gt;(config).Build();

try
{
    for (int i = 0; i &lt; 5; i++)
    {
        var message = new Message&lt;string, string&gt;
        {
          // Key = $&quot;UniqueKey&quot;,
          Value = $&quot;Hello Kafka {i}&quot;
        };

        var deliveryResult = await producer.ProduceAsync(topic, message);
        Console.WriteLine($&quot;sent to partition {deliveryResult.Partition} @ offset {deliveryResult.Offset} {deliveryResult.Status} {deliveryResult.Key} {deliveryResult.Value}&quot;);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><ul><li><code>Acks = Acks.Leader</code>，且<code>不指定Key</code>的时候，输出如下，信息被放入了<code>不同</code>的分区</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>sent to partition [9] @ offset 41534 Persisted  Hello Kafka 0
sent to partition [8] @ offset 45434 Persisted  Hello Kafka 1
sent to partition [9] @ offset 41535 Persisted  Hello Kafka 2
sent to partition [9] @ offset 41536 Persisted  Hello Kafka 3
sent to partition [1] @ offset 47045 Persisted  Hello Kafka 4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><ul><li><code>Acks = Acks.Leader</code>，且<code>指定Key</code>的时候，输出如下，信息被放入了<code>相同</code>的分区，从offset可以看出是依次进入的。</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>sent to partition [10] @ offset 47277 Persisted UniqueKey Hello Kafka 0
sent to partition [10] @ offset 47278 Persisted UniqueKey Hello Kafka 1
sent to partition [10] @ offset 47279 Persisted UniqueKey Hello Kafka 2
sent to partition [10] @ offset 47280 Persisted UniqueKey Hello Kafka 3
sent to partition [10] @ offset 47281 Persisted UniqueKey Hello Kafka 4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><ul><li><code>Acks = Acks.None</code>，输出如下，写入状态为<code>PossiblyPersisted</code>，分区固定，但是offset未确定。</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>sent to partition [10] @ offset Unset [-1001] PossiblyPersisted UniqueKey Hello Kafka 0
sent to partition [10] @ offset Unset [-1001] PossiblyPersisted UniqueKey Hello Kafka 1
sent to partition [10] @ offset Unset [-1001] PossiblyPersisted UniqueKey Hello Kafka 2
sent to partition [10] @ offset Unset [-1001] PossiblyPersisted UniqueKey Hello Kafka 3
sent to partition [10] @ offset Unset [-1001] PossiblyPersisted UniqueKey Hello Kafka 4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="消费者如何工作"><a href="#消费者如何工作" class="header-anchor">#</a> 消费者如何工作？</h2> <ul><li>消费者一定需要指定一个消费主题</li> <li>按照消费者组管理消费者，一个消费者一定属于某个组，如果没有指定组，则自动生成一个，一个消费者组共享一个进度，即一个消息只能被组中的某个消费者消费，不能重复消费。</li> <li>消费者组的进度被放入一个系统主题<code>__consumer_offsets</code>中，key为&lt;组ID,主题,分区&gt;,值为<code>offset、时间戳等相关信息</code></li> <li>一个消费者可以同时消费一个或者多个分区, 但是一个分区只能被一个消费者使用，如果有多余的消费者，则处于空闲状态</li> <li><img src="/assets/img/kafka-consumer-partition.1c896e73.jpg" alt="kafka-consumer-partition.jpg"></li> <li>消费的消费记录的确认即消费已经处理过的Offset可以自动提交或者手动提交，这个需要业务场景需要而定，如果需要业务确认才能commit可以使用手动提交。</li></ul> <h3 id="消费的次数保证"><a href="#消费的次数保证" class="header-anchor">#</a> 消费的次数保证</h3> <p>消息的消费次数是消费者来感受的，但是次数却是消费链路保证的。</p> <h4 id="最多一次"><a href="#最多一次" class="header-anchor">#</a> 最多一次</h4> <ul><li>消息可能丢失也可能被处理，但最多只会被处理一次。</li> <li>acks=0，调用写入方法后无论成功与否都不重试，就是最多一次</li></ul> <h4 id="最少一次"><a href="#最少一次" class="header-anchor">#</a> 最少一次</h4> <ul><li>消息不会丢失，但可能被处理多次</li> <li>acks=1或者acks=-1，调用写入方法成功了结束，中间有任何失败(网络问题)都重试，最少保证成功写入一次</li></ul> <h4 id="恰好一次"><a href="#恰好一次" class="header-anchor">#</a> 恰好一次</h4> <ul><li>消息被处理且只会被处理一次，如何实现呢，我们来看幂等和事务</li></ul> <h3 id="幂等"><a href="#幂等" class="header-anchor">#</a> 幂等</h3> <ul><li>幂等这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。</li> <li>幂等性最大的优势在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态。</li> <li>开启幂等性的时候，acks不允许为0或者1，只能是-1</li> <li>对每个消息引入了<code>producer id</code>和<code>sequence number</code>，<code>producer id</code>是一个producer会话的id，即幂等性是在同一个会话的上下文中, <code>sequence number</code>是本会话期的消息编号，broker如果遇到&lt;producerid, sequence number&gt;重复的消息会丢弃。</li> <li>非常重要的一点是，幂等性是一种kafka的<code>自我承诺</code>，用户无法干预，因为<code>没法指定消息的sequence number和producerid</code>，用户如果想要这个功能，只要开启这个功能就可以享受服务了。</li> <li>下面我们来观察一下，进入到配置的<code>log.dirs</code>目录下，可以看到格式为<code>topicname-partion</code>的目录，里面存放的是某个主题某个分区的日志数据，我们使用<code>/KAFKA-HOME-BIN/kafka-dump-log.sh --files ./00000000000000000000.log --print-data-log</code>可以看到，如果没有开启幂等性，Producer写入消息，日志格式如下</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>baseOffset: 39071 lastOffset: 39071 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 10 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 703960 CreateTime: 1742267672468 size: 91 magic: 2 compresscodec: none crc: 702011205 isvalid: true
| offset: 39071 CreateTime: 1742267672468 keySize: 10 valueSize: 13 sequence: -1 headerKeys: [] key: UniqueKey2 payload: Hello Kafka 4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>施加了幂等性后(Producer的配置项<code>EnableIdempotence</code>设置为true)，Producer写入消息，日志格式如下，最大的区别就是<code>sequence</code>和<code>producerId</code>都进行了赋值</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>baseOffset: 39076 lastOffset: 39076 count: 1 baseSequence: 4 lastSequence: 4 producerId: 3004 producerEpoch: 0 partitionLeaderEpoch: 10 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 704415 CreateTime: 1742268279113 size: 91 magic: 2 compresscodec: none crc: 402787861 isvalid: true
| offset: 39076 CreateTime: 1742268279113 keySize: 10 valueSize: 13 sequence: 4 headerKeys: [] key: UniqueKey2 payload: Hello Kafka 4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="事务"><a href="#事务" class="header-anchor">#</a> 事务</h3> <ul><li>事务最初的设计初衷，是为了流处理而设计的，或者说为<code>read-process-write</code>模式而设计的</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>We designed transactions in Kafka primarily for applications that exhibit a &quot;read-process-write&quot; pattern where the reads and writes are from and to asynchronous data streams such as Kafka topics. Such applications are more popularly known as stream processing applications.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>事务的引入是因为幂等性仅能保证消息不重复，但无法确保更高级别的一致性,比如金融领域保证<code>Exactly Once Semantics</code>，特别是针对<code>consume, transform, produce</code>这个模式。</li> <li>事务的执行流程数据存储在内部主题<code>__transaction_state</code>中，有50个分区</li> <li>事务引入了<code>Transaction Corordinator</code>事务协调器来居中处理事务流程,<code>Transaction Coordinator</code>是一个运行在每个Kafka Broker上的模块，不是单独的进程</li> <li><code>事务Id可以复用</code>,如果事务id不变，则每次的ProducerId不变，但是producerEpoch会推进</li> <li>即使是<code>放弃的事务，在topic也会留下数据</code>，只不过状态是未提交，可以通过Consumer的IsolationLevel或者命令行中的<code>--isolation-level read_committed</code>来只读已提交的消息</li></ul> <h5 id="事务的流程"><a href="#事务的流程" class="header-anchor">#</a> 事务的流程</h5> <ul><li>第一阶段： 获取ProducerId，在事务模式下ProducerId是事务协调器生成器(非事务下则是Producer自己生成的)</li> <li>第二阶段： <code>consume-transform-produce</code>循环(其实没有consume这一步也行，只有producer也可以使用事务)
<ul><li>在事务期间，如果出现了新的分区，特别是消息的Key不指定的情况下，需要通知事务协调器</li> <li>正常的写消息</li> <li>通知事务协调器Offset</li> <li>通知消费者协调器Offset，消费者协调器将这些Offset持久化到<code>__consumer_offsets</code>topic中</li></ul></li> <li>第三阶段：提交或者放弃事务，如果提交事务则使用两阶段提交来同步事务的最终状态和对主题中的消息的状态修改。
<img src="/assets/img/kafka-transaction.1e26d645.jpg" alt="kafka-transaction"></li> <li>PS: 更多细节请参考文末引用的官方文档，本节仅作知识点概述。</li></ul> <h5 id="事务测试"><a href="#事务测试" class="header-anchor">#</a> 事务测试</h5> <div class="language- line-numbers-mode"><pre class="language-text"><code>var config = new ProducerConfig
{
    BootstrapServers = bootstrapServers,
    Acks = Acks.All,  
    EnableIdempotence = true, 
    MessageTimeoutMs = 5000,  
    TransactionalId = &quot;MyTxnId&quot;,
    TransactionTimeoutMs = 5000,
};
using var producer = new ProducerBuilder&lt;string, string&gt;(config).Build();
try
{
    producer.InitTransactions(TimeSpan.FromMicroseconds(30000));
    producer.BeginTransaction();
    for (int i = 0; i &lt; 5; i++)
    {
        var message = new Message&lt;string, string&gt;
        {
            Key = &quot;UniqueKey3&quot;,
            Value = $&quot;Hello Kafka {i}&quot;
        };
        var deliveryResult = await producer.ProduceAsync(topic, message);
        Console.WriteLine($&quot;sent to partition {deliveryResult.Partition} @ offset {deliveryResult.Offset} {deliveryResult.Status} {deliveryResult.Key} {deliveryResult.Value}&quot;);
    }
    producer.CommitTransaction();
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><ul><li>还是使用<code>/KAFKA-HOME-BIN/kafka-dump-log.sh --files ./00000000000000000000.log --print-data-log</code>观察日志，可以看到<code>isTransactional</code>字段和<code>isControl</code>字段为true，并且多了<code>endTxnMarker: COMMIT coordinatorEpoch: 0</code>两个字段</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>baseOffset: 39122 lastOffset: 39122 count: 1 baseSequence: -1 lastSequence: -1 producerId: 4000 producerEpoch: 2 partitionLeaderEpoch: 10 isTransactional: true isControl: true deleteHorizonMs: OptionalLong.empty position: 708601 CreateTime: 1742270988178 size: 78 magic: 2 compresscodec: none crc: 4126398979 isvalid: true
| offset: 39122 CreateTime: 1742270988178 keySize: 4 valueSize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>查看日志验证<code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic __transaction_state --from-beginning --formatter &quot;kafka.coordinator.transaction.TransactionLog\$TransactionLogMessageFormatter&quot;</code>，如果被正常提交的事务，可以看到一个事务的详细的运行状态，信息太多了，我保留了一条完整的做参照，可以看到分区的信息</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>(transactionalId=MyTxnId, producerId=4000, producerEpoch=8, txnTimeoutMs=5000, state=Empty ...)
(transactionalId=MyTxnId, producerId=4000, producerEpoch=8, txnTimeoutMs=5000, state=Ongoing ...)
MyTxnId2::TransactionMetadata(transactionalId=MyTxnId2, producerId=4000, producerEpoch=8, txnTimeoutMs=5000, state=Ongoing, pendingState=None, topicPartitions=HashSet(mytest3-4, mytest3-5, mytest3-6, mytest3-0, mytest3-1, mytest3-2, mytest3-7, mytest3-8, mytest3-9), txnStartTimestamp=1742374937125, txnLastUpdateTimestamp=1742374937485)
(transactionalId=MyTxnId, producerId=4000, producerEpoch=8, txnTimeoutMs=5000, state=PrepareCommit ...)

(transactionalId=MyTxnId, producerId=4000, producerEpoch=8, txnTimeoutMs=5000, state=CompleteCommit ...)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>如果是放弃的事务可以看到如下的情况</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(transactionalId=MyTxnId2, producerId=5000, producerEpoch=1, txnTimeoutMs=5000, state=Empty, ...)
MyTxnId2::TransactionMetadata(transactionalId=MyTxnId2, producerId=5000, producerEpoch=1, txnTimeoutMs=5000, state=Ongoing, ...)
MyTxnId2::TransactionMetadata(transactionalId=MyTxnId2, producerId=5000, producerEpoch=1, txnTimeoutMs=5000, state=PrepareAbort, ...)
MyTxnId2::TransactionMetadata(transactionalId=MyTxnId2, producerId=5000, producerEpoch=1, txnTimeoutMs=5000, state=CompleteAbort, ...)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="小结"><a href="#小结" class="header-anchor">#</a> 小结</h3> <ul><li>不管是幂等还是事务，都是将消息准确的放入topic一次，但是在消费端能被消费几次，其实这两个都无法控制，这个其实是业务控制的，如果不自动commit，且不手动commit，则可以一直消费，哈哈。</li></ul> <h2 id="下面请老王给我们实战"><a href="#下面请老王给我们实战" class="header-anchor">#</a> 下面请老王给我们实战</h2> <ul><li>测试环境： 5个节点的KRaft模式的kafka集群，1,2,3为controller和worker，4，5为worker，使用docker-compose在一台机器上启动</li></ul> <h3 id="重要集群配置"><a href="#重要集群配置" class="header-anchor">#</a> 重要集群配置</h3> <ul><li>process.roles, broker/controller,broker/controller根据需要进行配置</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>process.roles=broker,controller 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>node.id,节点id，多节点每个需要不同</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>node.id=1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>controller.quorum.voters 控制节点列表，格式为<code>节点id@主机名或者ip:Port</code></li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>1@kafka01:9093,2@kafka02:9093,3@kafka03:9093
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>listeners，所有监听的端口信息，格式为<code>listeners = listener_name://host_name:port</code></li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>PLAINTEXT://:9092,CONTROLLER://:9093,MY_PLAINTEXT://0.0.0.0:19092
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>inter.broker.listener.name 内部通信listener</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>inter.broker.listener.name=PLAINTEXT
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>advertised.listeners 广播到客户端的listeners</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>advertised.listeners=PLAINTEXT://kafka01:9092,MY_PLAINTEXT://localhost:19092
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>controller.listener.names 控制器使用的listener的名字，kraft模式必填</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>controller.listener.names=CONTROLLER
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="集群"><a href="#集群" class="header-anchor">#</a> 集群</h3> <ul><li>查看集群状态，1,2,3控制着集群的状态投票，当前leader为2，4，5是观察者</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --status
ClusterId:              76BLQI7sT_ql1mBfKsOk9Q
LeaderId:               2
LeaderEpoch:            91
HighWatermark:          9445
MaxFollowerLag:         0
MaxFollowerLagTimeMs:   366
CurrentVoters:          [1,2,3]
CurrentObservers:       [4,5]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><ul><li>查看集群的复制状态，这里的LogEndOffset是kraft的元日志的偏移量</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --replication
NodeId  LogEndOffset    Lag     LastFetchTimestamp      LastCaughtUpTimestamp   Status  
2       9849            0       1742133742976           1742133742976           Leader  
1       9849            0       1742133742861           1742133742861           Follower
3       9849            0       1742133742861           1742133742861           Follower
4       9849            0       1742133742861           1742133742861           Observer
5       9849            0       1742133742861           1742133742861           Observer
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="topic"><a href="#topic" class="header-anchor">#</a> Topic</h3> <ul><li>查看所有topic</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --list --bootstrap-server localhost:9092
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>创建topic，复制因子为1，分区数为10</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 10 --topic mytest3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>查看</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic mytest3
Topic: mytest3  TopicId: gu9Q_X87QrqVgUcIu-ZvsA PartitionCount: 10      ReplicationFactor: 1    Configs: min.insync.replicas=2,segment.bytes=1073741824
  Topic: mytest3  Partition: 0    Leader: 3       Replicas: 3     Isr: 3  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 1    Leader: 4       Replicas: 4     Isr: 4  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 2    Leader: 5       Replicas: 5     Isr: 5  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 3    Leader: 1       Replicas: 1     Isr: 1  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 4    Leader: 2       Replicas: 2     Isr: 2  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 5    Leader: 5       Replicas: 5     Isr: 5  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 6    Leader: 1       Replicas: 1     Isr: 1  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 7    Leader: 2       Replicas: 2     Isr: 2  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 8    Leader: 4       Replicas: 4     Isr: 4  Elr:    LastKnownElr: 
  Topic: mytest3  Partition: 9    Leader: 3       Replicas: 3     Isr: 3  Elr:    LastKnownElr: 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li>创建topic，复制因子为2，分区数为10</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 2 --partitions 10 --topic mytest4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic mytest4
Topic: mytest4  TopicId: svoLcSv7QbWfyMR4aCy3Cg PartitionCount: 10      ReplicationFactor: 2    Configs: min.insync.replicas=2,segment.bytes=1073741824
  Topic: mytest4  Partition: 0    Leader: 1       Replicas: 1,2   Isr: 1,2        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 1    Leader: 2       Replicas: 2,3   Isr: 2,3        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 2    Leader: 3       Replicas: 3,4   Isr: 3,4        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 3    Leader: 4       Replicas: 4,5   Isr: 4,5        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 4    Leader: 5       Replicas: 5,1   Isr: 5,1        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 5    Leader: 4       Replicas: 4,2   Isr: 4,2        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 6    Leader: 2       Replicas: 2,5   Isr: 2,5        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 7    Leader: 5       Replicas: 5,1   Isr: 5,1        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 8    Leader: 1       Replicas: 1,3   Isr: 1,3        Elr:    LastKnownElr: 
  Topic: mytest4  Partition: 9    Leader: 3       Replicas: 3,4   Isr: 3,4        Elr:    LastKnownElr: 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li>创建topic，复制因子为3，分区数为10</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 10 --topic mytest2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic mytest2 
Topic: mytest2  TopicId: 7j3HHWHdRWeBMnY61E23rg PartitionCount: 10      ReplicationFactor: 3    Configs: min.insync.replicas=2,segment.bytes=1073741824
  Topic: mytest2  Partition: 0    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 1    Leader: 2       Replicas: 2,3,4 Isr: 2,3,4      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 2    Leader: 3       Replicas: 3,4,5 Isr: 3,4,5      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 3    Leader: 4       Replicas: 4,5,1 Isr: 4,5,1      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 4    Leader: 5       Replicas: 5,1,2 Isr: 5,1,2      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 5    Leader: 2       Replicas: 2,4,1 Isr: 2,4,1      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 6    Leader: 4       Replicas: 4,1,3 Isr: 4,1,3      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 7    Leader: 1       Replicas: 1,3,5 Isr: 1,3,5      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 8    Leader: 3       Replicas: 3,5,2 Isr: 3,5,2      Elr:    LastKnownElr: 
  Topic: mytest2  Partition: 9    Leader: 5       Replicas: 5,2,4 Isr: 5,2,4      Elr:    LastKnownElr:
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li>创建topic，复制因子为4，分区数为10</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 4 --partitions 10 --topic mytest5
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic mytest5
Topic: mytest5  TopicId: jQyCQb32RwmWyPoe2X64Eg PartitionCount: 10      ReplicationFactor: 4    Configs: min.insync.replicas=2,segment.bytes=1073741824
  Topic: mytest5  Partition: 0    Leader: 4       Replicas: 4,5,1,2       Isr: 4,5,1,2    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 1    Leader: 5       Replicas: 5,1,2,3       Isr: 5,1,2,3    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 2    Leader: 1       Replicas: 1,2,3,4       Isr: 1,2,3,4    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 3    Leader: 2       Replicas: 2,3,4,5       Isr: 2,3,4,5    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 4    Leader: 3       Replicas: 3,4,5,1       Isr: 3,4,5,1    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 5    Leader: 1       Replicas: 1,5,4,2       Isr: 1,5,4,2    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 6    Leader: 5       Replicas: 5,4,2,3       Isr: 5,4,2,3    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 7    Leader: 4       Replicas: 4,2,3,1       Isr: 4,2,3,1    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 8    Leader: 2       Replicas: 2,3,1,5       Isr: 2,3,1,5    Elr:    LastKnownElr: 
  Topic: mytest5  Partition: 9    Leader: 3       Replicas: 3,1,5,4       Isr: 3,1,5,4    Elr:    LastKnownElr:
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li>创建topic，复制因子为5，分区数为10</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 5 --partitions 10 --topic mytest
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic mytest
Topic: mytest   TopicId: 7cGDkw4qT3C_tSK1KBDiOQ PartitionCount: 10      ReplicationFactor: 5    Configs: min.insync.replicas=2,segment.bytes=1073741824
  Topic: mytest   Partition: 0    Leader: 1       Replicas: 1,2,3,4,5     Isr: 1,2,3,4,5  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 1    Leader: 2       Replicas: 2,3,4,5,1     Isr: 2,3,4,5,1  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 2    Leader: 3       Replicas: 3,4,5,1,2     Isr: 3,4,5,1,2  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 3    Leader: 4       Replicas: 4,5,1,2,3     Isr: 4,5,1,2,3  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 4    Leader: 5       Replicas: 5,1,2,3,4     Isr: 5,1,2,3,4  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 5    Leader: 4       Replicas: 4,2,1,3,5     Isr: 4,2,1,3,5  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 6    Leader: 2       Replicas: 2,1,3,5,4     Isr: 2,1,3,5,4  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 7    Leader: 1       Replicas: 1,3,5,4,2     Isr: 1,3,5,4,2  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 8    Leader: 3       Replicas: 3,5,4,2,1     Isr: 3,5,4,2,1  Elr:    LastKnownElr: 
  Topic: mytest   Partition: 9    Leader: 5       Replicas: 5,4,2,1,3     Isr: 5,4,2,1,3  Elr:    LastKnownElr:
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li>尝试创建复制因子为7的topic</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 7 --partitions 10 --topic mytest8
The target replication factor of 7 cannot be reached because only 5 broker(s) are registered.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>对test2增加topic的分区个数，原有10个</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic mytest2 --partitions 11
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>对test2减少topic的分区个数，现有11个，结果不允许</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic mytest2 --partitions 9
Error while executing topic command : The topic mytest2 currently has 11 partition(s); 9 would not be an increase.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>删除topic</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-topics.sh --bootstrap-server localhost:9092 --topic mytest --delete 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>总结来看
<ol><li>ReplicationFactor的数目不允许大于节点的个数N，允许范围是[1,N];</li> <li>分区个数允许增加，不允许较少;</li> <li>即使复制因子为1，每个分区也有一个leader.</li></ol></li></ul> <h3 id="生产者命令"><a href="#生产者命令" class="header-anchor">#</a> 生产者命令</h3> <ul><li>Console写入数据</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-console-producer.sh --broker-list localhost:9092 --topic mytest2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>一口气写入一堆数据</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-producer-perf-test.sh  --topic mytest2 --throughput  -1  --record-size 10 --num-records 500000 --producer-props bootstrap.servers=localhost:9092
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="消费者命令"><a href="#消费者命令" class="header-anchor">#</a> 消费者命令</h3> <ul><li>创建一个消费者，会自动生成组</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code> ./kafka-console-consumer.sh --bootstrap-server localhost:9092  --topic mytest2 --from-beginning
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>创建某个组的消费者</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092  --topic mytest2 --from-beginning --group test2-consumer-g
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>查看所有消费组</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-consumer-groups.sh --list --bootstrap-server localhost:9092
console-consumer-9097
console-consumer-91257
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><ul><li>查看消费组的详情，该组消费了test2一部分的数据，但是有大量的数据没有被处理，见LAG的值</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test2-consumer-g
GROUP            TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
test2-consumer-g mytest2         2          23180           41732           18552           -               -               -
test2-consumer-g mytest2         3          0               43680           43680           -               -               -
test2-consumer-g mytest2         4          50258           50258           0               -               -               -
test2-consumer-g mytest2         5          47027           47027           0               -               -               -
test2-consumer-g mytest2         0          0               39061           39061           -               -               -
test2-consumer-g mytest2         1          47018           47018           0               -               -               -
test2-consumer-g mytest2         10         0               47248           47248           -               -               -
test2-consumer-g mytest2         6          0               53099           53099           -               -               -
test2-consumer-g mytest2         7          0               43952           43952           -               -               -
test2-consumer-g mytest2         8          0               45408           45408           -               -               -
test2-consumer-g mytest2         9          41517           41517           0               -               -               -r
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>如果有消费者活跃的话，输出大体如下，LAG都变为了0，有3个消费者负责10个分区</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>GROUP	            TOPIC	  PARTITION	  CURRENT-OFFSET	LOG-END-OFFSET	  LAG	CONSUMER-ID   	
test2-consumer-g	mytest2	2	          41732	          41732	            0	  console-consumer-36344d57-d0be-4020-aacb-48d594850c46	
test2-consumer-g	mytest2	3	          43680	          43680	            0	  console-consumer-36344d57-d0be-4020-aacb-48d594850c46	
test2-consumer-g	mytest2	0	          39061	          39061	            0	  console-consumer-36344d57-d0be-4020-aacb-48d594850c46	
test2-consumer-g	mytest2	1	          47018	          47018	            0	  console-consumer-36344d57-d0be-4020-aacb-48d594850c46	
test2-consumer-g	mytest2	4	          50258	          50258	            0	  console-consumer-c1f08ee5-8658-4666-9b8f-894d43d118e3	
test2-consumer-g	mytest2	5	          47027	          47027	            0	  console-consumer-c1f08ee5-8658-4666-9b8f-894d43d118e3	
test2-consumer-g	mytest2	6	          53099	          53099	            0	  console-consumer-c1f08ee5-8658-4666-9b8f-894d43d118e3	
test2-consumer-g	mytest2	7	          43952	          43952	            0	  console-consumer-c1f08ee5-8658-4666-9b8f-894d43d118e3	
test2-consumer-g	mytest2	10	        47248	          47248	            0	  console-consumer-cad6c9c0-72d5-407a-9aff-abcba18a2438	
test2-consumer-g	mytest2	8	          45408	          45408	            0	  console-consumer-cad6c9c0-72d5-407a-9aff-abcba18a2438	
test2-consumer-g	mytest2	9	          41517	          41517	            0	  console-consumer-cad6c9c0-72d5-407a-9aff-abcba18a2438	

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>查看组成员，最后一列的#PARTITIONS表示该消费者分配到的分区的个数，<code>但是如果消费者过多的话，可能会被闲置</code>，测试的时候遇到过。</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code> &gt; ./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups --members
GROUP            CONSUMER-ID                                           HOST            CLIENT-ID        #PARTITIONS     
test2-consumer-g console-consumer-cad6c9c0-72d5-407a-9aff-abcba18a2438 /192.168.16.2   console-consumer 5               
test2-consumer-g console-consumer-36344d57-d0be-4020-aacb-48d594850c46 /192.168.16.7   console-consumer 6 

增加了一个同组消费者后变为
GROUP            CONSUMER-ID                                           HOST            CLIENT-ID        #PARTITIONS     
test2-consumer-g console-consumer-cad6c9c0-72d5-407a-9aff-abcba18a2438 /192.168.16.2   console-consumer 3               
test2-consumer-g console-consumer-36344d57-d0be-4020-aacb-48d594850c46 /192.168.16.7   console-consumer 4               
test2-consumer-g console-consumer-c1f08ee5-8658-4666-9b8f-894d43d118e3 /192.168.16.3   console-consumer 4 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><ul><li>查看组的offset的信息</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>&gt; ./kafka-console-consumer.sh --bootstrap-server localhost:9092  --topic __consumer_offsets --from-beginning --group test2-consumer-g --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot;

[test2-consumer-g,mytest2,5]::OffsetAndMetadata(offset=47027, leaderEpoch=Optional[0], metadata=, commitTimestamp=1742142162897, expireTimestamp=None)
[test2-consumer-g,mytest2,6]::OffsetAndMetadata(offset=53099, leaderEpoch=Optional[0], metadata=, commitTimestamp=1742142162897, expireTimestamp=None)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>本文从一个问题出发，引出消息队列kafka，然后针对kafka的角色和功能展开分析，介绍了分区和副本的使用方式，深入探讨了生产者的工作原理、消费者的工作原理，最后通过部署环境来演示相关命令的使用与效果。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>由于涉及到的内容比较多难免有所疏漏，欢迎大佬补充与评论，如有错误，也望不吝指出，感谢。
微信公众号为“吹风的坚果”，欢迎关注，定期更新优质的计算机文章。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="引用"><a href="#引用" class="header-anchor">#</a> 引用</h2> <ul><li><a href="https://www.confluent.io/blog/transactions-apache-kafka/" target="_blank" rel="noopener noreferrer">confluent-kafka-transaction<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit?pli=1&amp;tab=t.0" target="_blank" rel="noopener noreferrer">Exactly Once Delivery and Transactional<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.confluent.io/kafka/design/replication.html" target="_blank" rel="noopener noreferrer">confluent-replication<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://developer.confluent.io/courses/architecture/data-replication/" target="_blank" rel="noopener noreferrer">confluent-data-replication<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.confluent.io/kafka/design/consumer-design.html" target="_blank" rel="noopener noreferrer">consumer-design<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.confluent.io/blog/hands-free-kafka-replication-a-lesson-in-operational-simplicity/" target="_blank" rel="noopener noreferrer">free-kafka-replication-a-lesson-in-operational-simplicity<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/insight/hdd-2-mem.html" class="prev">
        磁盘和内存如何聊天
      </a></span> <!----></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.598d8060.js" defer></script><script src="/assets/js/2.4f2e74d3.js" defer></script><script src="/assets/js/9.d75e3788.js" defer></script>
  </body>
</html>
